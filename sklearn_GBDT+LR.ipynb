{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现GBDT+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_50420/2902806566.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \tmin_samples_split=900)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain_new_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm1 = GradientBoostingClassifier(n_estimators=50, \n",
    "\trandom_state=10, subsample=0.6, max_depth=7,\n",
    "\tmin_samples_split=900)\n",
    "gbm1.fit(X_train, Y_train)\n",
    "\n",
    "train_new_feature = gbm1.apply(X_train)\n",
    "train_new_feature = train_new_feature.reshape(-1, 50)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train_new_feature)\n",
    "\n",
    "print('每一个特征的最大取值数目:', enc.n_values_)\n",
    "print('所有特征的取值数目总和:', enc.n_values_.sum())\n",
    "\n",
    "train_new_feature2 = np.array(enc.transform(train_new_feature).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/s3hrf4f94bx7d661b9kg76v80000gn/T/ipykernel_50420/4246293797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mskt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mscore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mscore_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class gbdt_lr(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, gbdt=None, lr=None,gbdt_params=None,lr_params=None,cv=CountVectorizer(analyzer='word',preprocessor=None,ngram_range=(1,1),stop_words=None,min_df=0,)):\n",
    "        self.gbdt=gbdt(**gbdt_params)\n",
    "        self.lr=lr(**lr_params)\n",
    "        self.cv=cv\n",
    "    def fit(self, X, y):\n",
    "        self.gbdt.fit(X,y)\n",
    "        leaf = (self.gbdt.predict(X, pred_leaf=True)).astype(str).tolist()\n",
    "\n",
    "        leaf=[' '.join(item) for item in leaf]\n",
    "        self.result=self.cv.fit_transform(leaf)\n",
    "        X = self.lr.fit(self.result,y)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        leaf=self.gbdt.predict(X, pred_leaf=True)\n",
    "        leaf = (self.gbdt.predict(X, pred_leaf=True)).astype(str).tolist()\n",
    "        leaf=[' '.join(item) for item in leaf]\n",
    "        result=self.cv.transform(leaf)\n",
    "        \n",
    "        return self.lr.predict_proba(result)\n",
    "\n",
    "skt=StratifiedKFold(5,shuffle=True)\n",
    "\n",
    "splits = skt.split(X, y)\n",
    "score_train = []\n",
    "score_valid = []\n",
    "clfs=[]\n",
    "X=pd.DataFrame(X)\n",
    "y=pd.DataFrame(y)\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train, X_valid = X.iloc[train_index].values, X.iloc[valid_index].values\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "\n",
    "    clf = clf=gbdt_lr(gbdt=lgb.LGBMClassifier,gbdt_params={'n_estimators':500},lr=LogisticRegression,lr_params={'C':1.0})\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred_train = clf.predict_proba(X_train)[:,1]\n",
    "    y_pred_valid = clf.predict_proba(X_valid)[:,1]\n",
    "\n",
    "    score_train.append(roc_auc_score(y_train,y_pred_train))\n",
    "    score_valid.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbee7842ce8ba476870a006d5d5b68f11cea175afb0fea017b7f81beccf88892"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
