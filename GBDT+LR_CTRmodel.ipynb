{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT+LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "- 训练三个模型对数据进行预测\n",
    "- 分别是LR模型、GBDT模型和两者的组合模型\n",
    "- GBDT负责对各个特征进行交叉，把原始特征向量转换为新的离散型特征向量，然后再使用逻辑回归模型\n",
    "- 然后分别观察它们的预测效果\n",
    "\n",
    "特征的处理方式：\n",
    "- 逻辑回归模型：连续特征归一化， 离散特征one-hot编码\n",
    "- GBDT模型：离散特征one-hot编码（树模型连续特征不需要归一化）\n",
    "- GBDT+LR模型：离散特征one-hot编码（由于LR使用的特征是GBDT的输出， 原数据依然是GBDT进行处理， 所以只需要离散特征one-hot编码）\n",
    "\n",
    "任务： \n",
    "- 开发预测广告点击率(CTR)的模型\n",
    "- 即给定一个用户和他正在访问的页面，预测他点击给定广告的概率\n",
    "\n",
    "Dataset：\n",
    "- Label：目标变量，0表示未点击， 1表示点击\n",
    "- l1-l13: 13列的数值特征，大部分是计数特征\n",
    "- C1-C26: 26列的分类特征，这些特征的值离散成了32位的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "import gc\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set\n",
    "\n",
    "path = '/Users/quzihanwu/Desktop/GBDT+LR建模/TSG_RecommenderSystem/data/'\n",
    "df_train = pd.read_csv(path + 'train.csv')\n",
    "df_test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000743</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000159</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001166</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000318</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000924</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>10000835</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>10001216</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>10001653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>10000559</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>10000684</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  Label   I1   I2    I3    I4      I5     I6     I7    I8  ...  \\\n",
       "0     10000743      1  1.0    0   1.0   NaN   227.0    1.0  173.0  18.0  ...   \n",
       "1     10000159      1  4.0    1   1.0   2.0    27.0    2.0    4.0   2.0  ...   \n",
       "2     10001166      1  0.0  806   NaN   NaN  1752.0  142.0    2.0   0.0  ...   \n",
       "3     10000318      0  2.0   -1  42.0  14.0   302.0   38.0   25.0  38.0  ...   \n",
       "4     10000924      1  0.0   57   2.0   1.0  2891.0    2.0   35.0   1.0  ...   \n",
       "...        ...    ...  ...  ...   ...   ...     ...    ...    ...   ...  ...   \n",
       "1594  10000835      0  NaN    8   1.0   1.0    43.0    NaN    0.0   1.0  ...   \n",
       "1595  10001216      0  8.0    2  20.0   8.0    36.0    9.0    8.0  10.0  ...   \n",
       "1596  10001653      0  0.0    1   2.0  12.0  4877.0  140.0   13.0  34.0  ...   \n",
       "1597  10000559      0  NaN    2   NaN   1.0  1972.0    NaN    0.0   1.0  ...   \n",
       "1598  10000684      1  NaN   34   3.0   4.0     NaN    NaN    0.0   4.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9       NaN  bcdee96c   \n",
       "1     07c540c4  92555263       NaN       NaN  242bb710       NaN  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2       NaN  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21       NaN  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe       NaN       NaN  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be       NaN  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11       NaN       NaN  7453e535       NaN  dbb486d7   \n",
       "1597  e5ba7672  817481a8       NaN       NaN  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5       NaN       NaN  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11       NaN       NaN  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493       NaN       NaN  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec       NaN       NaN  \n",
       "1597  60efe6e6       NaN       NaN  \n",
       "1598  8fc66e78       NaN       NaN  \n",
       "\n",
       "[1599 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>7119e567</td>\n",
       "      <td>1d04f4a4</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>d5f54153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>a9d771cd</td>\n",
       "      <td>c9f3bea7</td>\n",
       "      <td>0a47000d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17881.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>51369abb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d4b6b7e8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>37821b83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>bd17c3da</td>\n",
       "      <td>966f1c31</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>1d1393f4</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>010f6491</td>\n",
       "      <td>49d68486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1471</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>1f9656b8</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>602ce342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>70b6702c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2972.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>87c6f83c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bf8efd4c</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>f96a556f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>10001453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>d16737e3</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>edc49a33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93bad2c0</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>80dd0a5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>10000360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>5162930e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12965bb8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>71292dbb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>10001809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>a78bd508</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>c2a93b37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>2fede552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>10000769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>a1d0cc4f</td>\n",
       "      <td>c68db44a</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>3b1ae854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>57e2c6c9</td>\n",
       "      <td>1575c75f</td>\n",
       "      <td>7132fed8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>10000563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>7b49e3d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dfcfc3fa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>aee52b6f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id   I1    I2    I3    I4       I5     I6    I7    I8     I9  ...  \\\n",
       "0    10000405  NaN    -1   NaN   NaN   8020.0   26.0   6.0   0.0   80.0  ...   \n",
       "1    10001189  NaN    -1   NaN   NaN  17881.0    9.0   8.0   0.0    0.0  ...   \n",
       "2    10000674  0.0     0   2.0  13.0   2904.0  104.0   1.0   3.0  100.0  ...   \n",
       "3    10001358  0.0  1471  51.0   4.0   1573.0   63.0   1.0   4.0   13.0  ...   \n",
       "4    10000810  0.0    16   9.0  17.0   2972.0  621.0  13.0  42.0  564.0  ...   \n",
       "..        ...  ...   ...   ...   ...      ...    ...   ...   ...    ...  ...   \n",
       "395  10001453  1.0     0   1.0   NaN    149.0    5.0   1.0   0.0    0.0  ...   \n",
       "396  10000360  NaN    -1   NaN   NaN      NaN    NaN   0.0   0.0    6.0  ...   \n",
       "397  10001809  0.0   300   4.0   NaN   4622.0   25.0  20.0   6.0   55.0  ...   \n",
       "398  10000769  1.0     1   2.0   1.0      5.0    1.0   1.0   1.0    1.0  ...   \n",
       "399  10000563  NaN     2   NaN   NaN  36144.0    NaN   NaN  36.0    NaN  ...   \n",
       "\n",
       "          C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0    e5ba7672  7119e567  1d04f4a4  b1252a9d  d5f54153       NaN  32c7478e   \n",
       "1    e5ba7672  51369abb       NaN       NaN  d4b6b7e8       NaN  32c7478e   \n",
       "2    e5ba7672  bd17c3da  966f1c31  a458ea53  1d1393f4  ad3062eb  32c7478e   \n",
       "3    d4bb7bd8  1f9656b8  21ddcdc9  b1252a9d  602ce342       NaN  3a171ecb   \n",
       "4    e5ba7672  87c6f83c       NaN       NaN  bf8efd4c  c9d4222a  423fab69   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  d4bb7bd8  5aed7436  d16737e3  a458ea53  edc49a33       NaN  93bad2c0   \n",
       "396  2005abd1  5162930e       NaN       NaN  12965bb8       NaN  32c7478e   \n",
       "397  8efede7f  a78bd508  21ddcdc9  5840adea  c2a93b37       NaN  3a171ecb   \n",
       "398  d4bb7bd8  a1d0cc4f  c68db44a  a458ea53  3b1ae854       NaN  32c7478e   \n",
       "399  e5ba7672  7b49e3d2       NaN       NaN  dfcfc3fa       NaN  423fab69   \n",
       "\n",
       "          C24       C25       C26  \n",
       "0    a9d771cd  c9f3bea7  0a47000d  \n",
       "1    37821b83       NaN       NaN  \n",
       "2    3fdb382b  010f6491  49d68486  \n",
       "3    1793a828  e8b83407  70b6702c  \n",
       "4    f96a556f       NaN       NaN  \n",
       "..        ...       ...       ...  \n",
       "395  3fdb382b  e8b83407  80dd0a5b  \n",
       "396  71292dbb       NaN       NaN  \n",
       "397  1793a828  e8b83407  2fede552  \n",
       "398  57e2c6c9  1575c75f  7132fed8  \n",
       "399  aee52b6f       NaN       NaN  \n",
       "\n",
       "[400 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# 去掉 Id 列\n",
    "df_train.drop(['Id'], axis=1, inplace=True)\n",
    "df_test.drop(['Id'], axis=1, inplace=True)\n",
    "\n",
    "# 测试集新增 Label 列\n",
    "df_test['Label'] = -1\n",
    "\n",
    "# 合并测试集和训练集\n",
    "data = pd.concat([df_train, df_test])\n",
    "\n",
    "# 填充缺失值\n",
    "data.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>-1</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>-1</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>-1</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>d16737e3</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>edc49a33</td>\n",
       "      <td>-1</td>\n",
       "      <td>93bad2c0</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>80dd0a5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>5162930e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12965bb8</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>71292dbb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4622.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>a78bd508</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>c2a93b37</td>\n",
       "      <td>-1</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>2fede552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d4bb7bd8</td>\n",
       "      <td>a1d0cc4f</td>\n",
       "      <td>c68db44a</td>\n",
       "      <td>a458ea53</td>\n",
       "      <td>3b1ae854</td>\n",
       "      <td>-1</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>57e2c6c9</td>\n",
       "      <td>1575c75f</td>\n",
       "      <td>7132fed8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36144.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>7b49e3d2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>dfcfc3fa</td>\n",
       "      <td>-1</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>aee52b6f</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label   I1   I2    I3    I4       I5     I6     I7    I8     I9  ...  \\\n",
       "0        1  1.0    0   1.0  -1.0    227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1        1  4.0    1   1.0   2.0     27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2        1  0.0  806  -1.0  -1.0   1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3        0  2.0   -1  42.0  14.0    302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4        1  0.0   57   2.0   1.0   2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "..     ...  ...  ...   ...   ...      ...    ...    ...   ...    ...  ...   \n",
       "395     -1  1.0    0   1.0  -1.0    149.0    5.0    1.0   0.0    0.0  ...   \n",
       "396     -1 -1.0   -1  -1.0  -1.0     -1.0   -1.0    0.0   0.0    6.0  ...   \n",
       "397     -1  0.0  300   4.0  -1.0   4622.0   25.0   20.0   6.0   55.0  ...   \n",
       "398     -1  1.0    1   2.0   1.0      5.0    1.0    1.0   1.0    1.0  ...   \n",
       "399     -1 -1.0    2  -1.0  -1.0  36144.0   -1.0   -1.0  36.0   -1.0  ...   \n",
       "\n",
       "          C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0    3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9        -1  bcdee96c   \n",
       "1    07c540c4  92555263        -1        -1  242bb710        -1  3a171ecb   \n",
       "2    07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2        -1  32c7478e   \n",
       "3    e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21        -1  423fab69   \n",
       "4    e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  d4bb7bd8  5aed7436  d16737e3  a458ea53  edc49a33        -1  93bad2c0   \n",
       "396  2005abd1  5162930e        -1        -1  12965bb8        -1  32c7478e   \n",
       "397  8efede7f  a78bd508  21ddcdc9  5840adea  c2a93b37        -1  3a171ecb   \n",
       "398  d4bb7bd8  a1d0cc4f  c68db44a  a458ea53  3b1ae854        -1  32c7478e   \n",
       "399  e5ba7672  7b49e3d2        -1        -1  dfcfc3fa        -1  423fab69   \n",
       "\n",
       "          C24       C25       C26  \n",
       "0    4d19a3eb  cb079c2d  456c12a0  \n",
       "1    72c78f11        -1        -1  \n",
       "2    8fc66e78  001f3601  f37f3967  \n",
       "3    1793a828  e8b83407  5cef228f  \n",
       "4    45ab94c8  2bf691b1  c84c4aec  \n",
       "..        ...       ...       ...  \n",
       "395  3fdb382b  e8b83407  80dd0a5b  \n",
       "396  71292dbb        -1        -1  \n",
       "397  1793a828  e8b83407  2fede552  \n",
       "398  57e2c6c9  1575c75f  7132fed8  \n",
       "399  aee52b6f        -1        -1  \n",
       "\n",
       "[1999 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label   I1   I2   I3   I4      I5     I6     I7    I8    I9  ...       C17  \\\n",
      "0      1  1.0    0  1.0 -1.0   227.0    1.0  173.0  18.0  50.0  ...  3486227d   \n",
      "1      1  4.0    1  1.0  2.0    27.0    2.0    4.0   2.0   2.0  ...  07c540c4   \n",
      "2      1  0.0  806 -1.0 -1.0  1752.0  142.0    2.0   0.0  50.0  ...  07c540c4   \n",
      "\n",
      "        C18       C19       C20       C21 C22       C23       C24       C25  \\\n",
      "0  e88ffc9d  c393dc22  b1252a9d  57c90cd9  -1  bcdee96c  4d19a3eb  cb079c2d   \n",
      "1  92555263        -1        -1  242bb710  -1  3a171ecb  72c78f11        -1   \n",
      "2  25c88e42  21ddcdc9  b1252a9d  a0136dd2  -1  32c7478e  8fc66e78  001f3601   \n",
      "\n",
      "        C26  \n",
      "0  456c12a0  \n",
      "1        -1  \n",
      "2  f37f3967  \n",
      "\n",
      "[3 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# 划分连续和离散特征\n",
    "\n",
    "continuous_fea = ['I'+str(i+1) for i in range(13)]\n",
    "category_fea = ['C'+str(i+1) for i in range(26)]\n",
    "\n",
    "print(data[: 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR\n",
    "def lr_model(data, category_fea, continuous_fea):\n",
    "    \"\"\"\n",
    "        逻辑回归建模\n",
    "        \n",
    "        :param data: df, 数据表\n",
    "        :param category_fea: list, 离散特征列\n",
    "        :param continuous_fea: list, 连续特征列\n",
    "    \"\"\"\n",
    "    \n",
    "    # 连续特征归一化\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in continuous_fea:\n",
    "        data[col] = scaler.fit_transform(data[col].values.reshape(-1, 1))\n",
    "    \n",
    "    # 离散特征one-hot编码\n",
    "    for col in category_fea:\n",
    "        onehot_feats = pd.get_dummies(data[col], prefix=col)\n",
    "        data.drop([col], axis=1, inplace=True)\n",
    "        data = pd.concat([data, onehot_feats], axis=1)\n",
    "    \n",
    "    # 拆分训练集和测试集\n",
    "    train = data[data['Label'] != -1]\n",
    "    target = train.pop('Label')\n",
    "    test = data[data['Label'] == -1]\n",
    "    test.drop(['Label'], axis=1, inplace=True)\n",
    "    \n",
    "    # 划分训练集\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=2020)\n",
    "\n",
    "    # 建立模型\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    tr_logloss = log_loss(y_train, lr.predict_proba(x_train)[:, 1])  # −(ylog(p)+(1−y)log(1−p)) log_loss\n",
    "    val_logloss = log_loss(y_val, lr.predict_proba(x_val)[:, 1])\n",
    "    print('tr_logloss: ', tr_logloss)\n",
    "    print('val_logloss: ', val_logloss)\n",
    "    \n",
    "    # 模型预测\n",
    "    y_pred = lr.predict_proba(test)[:, 1]  # predict_proba 返回n行k列的矩阵，第i行第j列上的数值是模型预测第i个预测样本为某个标签的概率，这里的1表示点击的概率\n",
    "    print('predict: ', y_pred[:10]) # 这里看前10个，预测为点击的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_logloss:  0.1242339516478198\n",
      "val_logloss:  0.44407245698797837\n",
      "predict:  [0.44783059 0.80628705 0.1756691  0.02070154 0.13984202 0.46490042\n",
      " 0.43386417 0.07089967 0.07121148 0.27896238]\n"
     ]
    }
   ],
   "source": [
    "lr_model(data.copy(), category_fea, continuous_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBDT\n",
    "\n",
    "def gbdt_model(data, category_fea, continuous_fea):\n",
    "    \"\"\"\n",
    "        GBDT建模\n",
    "        \n",
    "        :param data: df, 数据表\n",
    "        :param category_fea: list, 离散特征列\n",
    "        :param continuous_fea: list, 连续特征列\n",
    "    \"\"\"\n",
    "    \n",
    "    # 离散特征one-hot编码\n",
    "    for col in category_fea:\n",
    "        onehot_feats = pd.get_dummies(data[col], prefix=col)\n",
    "        data.drop([col], axis=1, inplace=True)\n",
    "        data = pd.concat([data, onehot_feats], axis=1)\n",
    "\n",
    "    # 拆分训练集和测试集\n",
    "    train = data[data['Label'] != -1]\n",
    "    target = train.pop('Label')\n",
    "    test = data[data['Label'] == -1]\n",
    "    test.drop(['Label'], axis=1, inplace=True)\n",
    "    \n",
    "    # 划分数据集\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=2020)\n",
    "    \n",
    "    # 建立模型\n",
    "    gbm = lgb.LGBMClassifier(boosting_type='gbdt',  # 这里用gbdt\n",
    "                             objective='binary', \n",
    "                             subsample=0.8,\n",
    "                             min_child_weight=0.5, \n",
    "                             colsample_bytree=0.7,\n",
    "                             num_leaves=100,\n",
    "                             max_depth=12,\n",
    "                             learning_rate=0.01,\n",
    "                             n_estimators=10000\n",
    "                            )\n",
    "    gbm.fit(x_train, y_train, \n",
    "            eval_set=[(x_train, y_train), (x_val, y_val)], \n",
    "            eval_names=['train', 'val'],\n",
    "            eval_metric='binary_logloss',\n",
    "            early_stopping_rounds=100,\n",
    "           )\n",
    "    \n",
    "    tr_logloss = log_loss(y_train, gbm.predict_proba(x_train)[:, 1])   # −(ylog(p)+(1−y)log(1−p)) log_loss\n",
    "    val_logloss = log_loss(y_val, gbm.predict_proba(x_val)[:, 1])\n",
    "    print('tr_logloss: ', tr_logloss)\n",
    "    print('val_logloss: ', val_logloss)\n",
    "    \n",
    "    # 模型预测\n",
    "    y_pred = gbm.predict_proba(test)[:, 1]  # predict_proba 返回n行k列的矩阵，第i行第j列上的数值是模型预测第i个预测样本为某个标签的概率，这里的1表示点击的概率\n",
    "    print('predict: ', y_pred[:10]) # 这里看前10个，预测为点击的概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's binary_logloss: 0.523857\tval's binary_logloss: 0.457806\n",
      "[2]\ttrain's binary_logloss: 0.521371\tval's binary_logloss: 0.457213\n",
      "[3]\ttrain's binary_logloss: 0.519084\tval's binary_logloss: 0.456616\n",
      "[4]\ttrain's binary_logloss: 0.516882\tval's binary_logloss: 0.456046\n",
      "[5]\ttrain's binary_logloss: 0.514449\tval's binary_logloss: 0.455649\n",
      "[6]\ttrain's binary_logloss: 0.512277\tval's binary_logloss: 0.455319\n",
      "[7]\ttrain's binary_logloss: 0.509973\tval's binary_logloss: 0.455039\n",
      "[8]\ttrain's binary_logloss: 0.507717\tval's binary_logloss: 0.454523\n",
      "[9]\ttrain's binary_logloss: 0.505668\tval's binary_logloss: 0.454546\n",
      "[10]\ttrain's binary_logloss: 0.503491\tval's binary_logloss: 0.454134\n",
      "[11]\ttrain's binary_logloss: 0.501469\tval's binary_logloss: 0.453151\n",
      "[12]\ttrain's binary_logloss: 0.499463\tval's binary_logloss: 0.452609\n",
      "[13]\ttrain's binary_logloss: 0.497257\tval's binary_logloss: 0.452419\n",
      "[14]\ttrain's binary_logloss: 0.495206\tval's binary_logloss: 0.451944\n",
      "[15]\ttrain's binary_logloss: 0.493127\tval's binary_logloss: 0.451356\n",
      "[16]\ttrain's binary_logloss: 0.491215\tval's binary_logloss: 0.451181\n",
      "[17]\ttrain's binary_logloss: 0.489258\tval's binary_logloss: 0.450615\n",
      "[18]\ttrain's binary_logloss: 0.487424\tval's binary_logloss: 0.450754\n",
      "[19]\ttrain's binary_logloss: 0.485589\tval's binary_logloss: 0.450428\n",
      "[20]\ttrain's binary_logloss: 0.483753\tval's binary_logloss: 0.450043\n",
      "[21]\ttrain's binary_logloss: 0.481871\tval's binary_logloss: 0.449924\n",
      "[22]\ttrain's binary_logloss: 0.480233\tval's binary_logloss: 0.449518\n",
      "[23]\ttrain's binary_logloss: 0.478629\tval's binary_logloss: 0.449086\n",
      "[24]\ttrain's binary_logloss: 0.476933\tval's binary_logloss: 0.448878\n",
      "[25]\ttrain's binary_logloss: 0.47504\tval's binary_logloss: 0.448413\n",
      "[26]\ttrain's binary_logloss: 0.473416\tval's binary_logloss: 0.44809\n",
      "[27]\ttrain's binary_logloss: 0.471608\tval's binary_logloss: 0.448072\n",
      "[28]\ttrain's binary_logloss: 0.469969\tval's binary_logloss: 0.447721\n",
      "[29]\ttrain's binary_logloss: 0.46833\tval's binary_logloss: 0.447358\n",
      "[30]\ttrain's binary_logloss: 0.466517\tval's binary_logloss: 0.447445\n",
      "[31]\ttrain's binary_logloss: 0.464722\tval's binary_logloss: 0.447317\n",
      "[32]\ttrain's binary_logloss: 0.463079\tval's binary_logloss: 0.447152\n",
      "[33]\ttrain's binary_logloss: 0.461319\tval's binary_logloss: 0.446674\n",
      "[34]\ttrain's binary_logloss: 0.459722\tval's binary_logloss: 0.446455\n",
      "[35]\ttrain's binary_logloss: 0.457986\tval's binary_logloss: 0.446345\n",
      "[36]\ttrain's binary_logloss: 0.456293\tval's binary_logloss: 0.446229\n",
      "[37]\ttrain's binary_logloss: 0.454638\tval's binary_logloss: 0.446135\n",
      "[38]\ttrain's binary_logloss: 0.452929\tval's binary_logloss: 0.445476\n",
      "[39]\ttrain's binary_logloss: 0.451349\tval's binary_logloss: 0.445208\n",
      "[40]\ttrain's binary_logloss: 0.449759\tval's binary_logloss: 0.444538\n",
      "[41]\ttrain's binary_logloss: 0.448181\tval's binary_logloss: 0.444151\n",
      "[42]\ttrain's binary_logloss: 0.446656\tval's binary_logloss: 0.443786\n",
      "[43]\ttrain's binary_logloss: 0.445243\tval's binary_logloss: 0.443472\n",
      "[44]\ttrain's binary_logloss: 0.443697\tval's binary_logloss: 0.443249\n",
      "[45]\ttrain's binary_logloss: 0.442193\tval's binary_logloss: 0.443062\n",
      "[46]\ttrain's binary_logloss: 0.440697\tval's binary_logloss: 0.442784\n",
      "[47]\ttrain's binary_logloss: 0.439353\tval's binary_logloss: 0.442828\n",
      "[48]\ttrain's binary_logloss: 0.437963\tval's binary_logloss: 0.442524\n",
      "[49]\ttrain's binary_logloss: 0.436672\tval's binary_logloss: 0.442423\n",
      "[50]\ttrain's binary_logloss: 0.435301\tval's binary_logloss: 0.442193\n",
      "[51]\ttrain's binary_logloss: 0.433889\tval's binary_logloss: 0.441743\n",
      "[52]\ttrain's binary_logloss: 0.432548\tval's binary_logloss: 0.441336\n",
      "[53]\ttrain's binary_logloss: 0.431017\tval's binary_logloss: 0.441085\n",
      "[54]\ttrain's binary_logloss: 0.429677\tval's binary_logloss: 0.440932\n",
      "[55]\ttrain's binary_logloss: 0.428271\tval's binary_logloss: 0.440676\n",
      "[56]\ttrain's binary_logloss: 0.42698\tval's binary_logloss: 0.44047\n",
      "[57]\ttrain's binary_logloss: 0.425539\tval's binary_logloss: 0.440397\n",
      "[58]\ttrain's binary_logloss: 0.424123\tval's binary_logloss: 0.440136\n",
      "[59]\ttrain's binary_logloss: 0.422809\tval's binary_logloss: 0.439885\n",
      "[60]\ttrain's binary_logloss: 0.42146\tval's binary_logloss: 0.439716\n",
      "[61]\ttrain's binary_logloss: 0.420068\tval's binary_logloss: 0.439454\n",
      "[62]\ttrain's binary_logloss: 0.418745\tval's binary_logloss: 0.439493\n",
      "[63]\ttrain's binary_logloss: 0.41755\tval's binary_logloss: 0.439334\n",
      "[64]\ttrain's binary_logloss: 0.416342\tval's binary_logloss: 0.439451\n",
      "[65]\ttrain's binary_logloss: 0.415058\tval's binary_logloss: 0.439173\n",
      "[66]\ttrain's binary_logloss: 0.413658\tval's binary_logloss: 0.43881\n",
      "[67]\ttrain's binary_logloss: 0.4123\tval's binary_logloss: 0.438656\n",
      "[68]\ttrain's binary_logloss: 0.410981\tval's binary_logloss: 0.438352\n",
      "[69]\ttrain's binary_logloss: 0.409717\tval's binary_logloss: 0.438017\n",
      "[70]\ttrain's binary_logloss: 0.408442\tval's binary_logloss: 0.437799\n",
      "[71]\ttrain's binary_logloss: 0.407242\tval's binary_logloss: 0.437543\n",
      "[72]\ttrain's binary_logloss: 0.406051\tval's binary_logloss: 0.437359\n",
      "[73]\ttrain's binary_logloss: 0.404727\tval's binary_logloss: 0.437274\n",
      "[74]\ttrain's binary_logloss: 0.403419\tval's binary_logloss: 0.437135\n",
      "[75]\ttrain's binary_logloss: 0.402132\tval's binary_logloss: 0.437162\n",
      "[76]\ttrain's binary_logloss: 0.401026\tval's binary_logloss: 0.437043\n",
      "[77]\ttrain's binary_logloss: 0.399681\tval's binary_logloss: 0.436681\n",
      "[78]\ttrain's binary_logloss: 0.398398\tval's binary_logloss: 0.436374\n",
      "[79]\ttrain's binary_logloss: 0.397186\tval's binary_logloss: 0.436306\n",
      "[80]\ttrain's binary_logloss: 0.395998\tval's binary_logloss: 0.436238\n",
      "[81]\ttrain's binary_logloss: 0.394678\tval's binary_logloss: 0.436146\n",
      "[82]\ttrain's binary_logloss: 0.393508\tval's binary_logloss: 0.436026\n",
      "[83]\ttrain's binary_logloss: 0.392385\tval's binary_logloss: 0.435897\n",
      "[84]\ttrain's binary_logloss: 0.391328\tval's binary_logloss: 0.435948\n",
      "[85]\ttrain's binary_logloss: 0.390191\tval's binary_logloss: 0.435803\n",
      "[86]\ttrain's binary_logloss: 0.389034\tval's binary_logloss: 0.435726\n",
      "[87]\ttrain's binary_logloss: 0.388039\tval's binary_logloss: 0.435854\n",
      "[88]\ttrain's binary_logloss: 0.3868\tval's binary_logloss: 0.435683\n",
      "[89]\ttrain's binary_logloss: 0.38566\tval's binary_logloss: 0.435685\n",
      "[90]\ttrain's binary_logloss: 0.384527\tval's binary_logloss: 0.435758\n",
      "[91]\ttrain's binary_logloss: 0.383388\tval's binary_logloss: 0.435756\n",
      "[92]\ttrain's binary_logloss: 0.38231\tval's binary_logloss: 0.435815\n",
      "[93]\ttrain's binary_logloss: 0.381094\tval's binary_logloss: 0.435682\n",
      "[94]\ttrain's binary_logloss: 0.379807\tval's binary_logloss: 0.435561\n",
      "[95]\ttrain's binary_logloss: 0.37872\tval's binary_logloss: 0.435383\n",
      "[96]\ttrain's binary_logloss: 0.377682\tval's binary_logloss: 0.435011\n",
      "[97]\ttrain's binary_logloss: 0.376613\tval's binary_logloss: 0.434783\n",
      "[98]\ttrain's binary_logloss: 0.375463\tval's binary_logloss: 0.434865\n",
      "[99]\ttrain's binary_logloss: 0.374318\tval's binary_logloss: 0.434926\n",
      "[100]\ttrain's binary_logloss: 0.373331\tval's binary_logloss: 0.435077\n",
      "[101]\ttrain's binary_logloss: 0.372209\tval's binary_logloss: 0.43519\n",
      "[102]\ttrain's binary_logloss: 0.371232\tval's binary_logloss: 0.434997\n",
      "[103]\ttrain's binary_logloss: 0.370158\tval's binary_logloss: 0.43491\n",
      "[104]\ttrain's binary_logloss: 0.369108\tval's binary_logloss: 0.434854\n",
      "[105]\ttrain's binary_logloss: 0.368046\tval's binary_logloss: 0.435009\n",
      "[106]\ttrain's binary_logloss: 0.366972\tval's binary_logloss: 0.434982\n",
      "[107]\ttrain's binary_logloss: 0.365952\tval's binary_logloss: 0.435174\n",
      "[108]\ttrain's binary_logloss: 0.365084\tval's binary_logloss: 0.435282\n",
      "[109]\ttrain's binary_logloss: 0.364023\tval's binary_logloss: 0.435066\n",
      "[110]\ttrain's binary_logloss: 0.363132\tval's binary_logloss: 0.43526\n",
      "[111]\ttrain's binary_logloss: 0.362204\tval's binary_logloss: 0.435537\n",
      "[112]\ttrain's binary_logloss: 0.361217\tval's binary_logloss: 0.435766\n",
      "[113]\ttrain's binary_logloss: 0.360214\tval's binary_logloss: 0.43583\n",
      "[114]\ttrain's binary_logloss: 0.35936\tval's binary_logloss: 0.435792\n",
      "[115]\ttrain's binary_logloss: 0.358383\tval's binary_logloss: 0.435522\n",
      "[116]\ttrain's binary_logloss: 0.357288\tval's binary_logloss: 0.435637\n",
      "[117]\ttrain's binary_logloss: 0.356216\tval's binary_logloss: 0.435376\n",
      "[118]\ttrain's binary_logloss: 0.355096\tval's binary_logloss: 0.435324\n",
      "[119]\ttrain's binary_logloss: 0.354101\tval's binary_logloss: 0.43536\n",
      "[120]\ttrain's binary_logloss: 0.353266\tval's binary_logloss: 0.435261\n",
      "[121]\ttrain's binary_logloss: 0.352268\tval's binary_logloss: 0.435374\n",
      "[122]\ttrain's binary_logloss: 0.351148\tval's binary_logloss: 0.435321\n",
      "[123]\ttrain's binary_logloss: 0.350471\tval's binary_logloss: 0.435319\n",
      "[124]\ttrain's binary_logloss: 0.349503\tval's binary_logloss: 0.435183\n",
      "[125]\ttrain's binary_logloss: 0.348856\tval's binary_logloss: 0.435206\n",
      "[126]\ttrain's binary_logloss: 0.348053\tval's binary_logloss: 0.435206\n",
      "[127]\ttrain's binary_logloss: 0.347443\tval's binary_logloss: 0.434997\n",
      "[128]\ttrain's binary_logloss: 0.346512\tval's binary_logloss: 0.434941\n",
      "[129]\ttrain's binary_logloss: 0.345885\tval's binary_logloss: 0.434922\n",
      "[130]\ttrain's binary_logloss: 0.345112\tval's binary_logloss: 0.43477\n",
      "[131]\ttrain's binary_logloss: 0.344716\tval's binary_logloss: 0.434628\n",
      "[132]\ttrain's binary_logloss: 0.343697\tval's binary_logloss: 0.434359\n",
      "[133]\ttrain's binary_logloss: 0.342596\tval's binary_logloss: 0.434238\n",
      "[134]\ttrain's binary_logloss: 0.341666\tval's binary_logloss: 0.434321\n",
      "[135]\ttrain's binary_logloss: 0.340742\tval's binary_logloss: 0.434473\n",
      "[136]\ttrain's binary_logloss: 0.340167\tval's binary_logloss: 0.43421\n",
      "[137]\ttrain's binary_logloss: 0.339296\tval's binary_logloss: 0.434303\n",
      "[138]\ttrain's binary_logloss: 0.338391\tval's binary_logloss: 0.434198\n",
      "[139]\ttrain's binary_logloss: 0.337404\tval's binary_logloss: 0.434061\n",
      "[140]\ttrain's binary_logloss: 0.336569\tval's binary_logloss: 0.434292\n",
      "[141]\ttrain's binary_logloss: 0.335612\tval's binary_logloss: 0.43427\n",
      "[142]\ttrain's binary_logloss: 0.334555\tval's binary_logloss: 0.434261\n",
      "[143]\ttrain's binary_logloss: 0.333721\tval's binary_logloss: 0.434249\n",
      "[144]\ttrain's binary_logloss: 0.332994\tval's binary_logloss: 0.434215\n",
      "[145]\ttrain's binary_logloss: 0.332136\tval's binary_logloss: 0.434258\n",
      "[146]\ttrain's binary_logloss: 0.331524\tval's binary_logloss: 0.434092\n",
      "[147]\ttrain's binary_logloss: 0.330627\tval's binary_logloss: 0.434013\n",
      "[148]\ttrain's binary_logloss: 0.330059\tval's binary_logloss: 0.434193\n",
      "[149]\ttrain's binary_logloss: 0.329078\tval's binary_logloss: 0.434141\n",
      "[150]\ttrain's binary_logloss: 0.328427\tval's binary_logloss: 0.434367\n",
      "[151]\ttrain's binary_logloss: 0.327484\tval's binary_logloss: 0.434264\n",
      "[152]\ttrain's binary_logloss: 0.326809\tval's binary_logloss: 0.434526\n",
      "[153]\ttrain's binary_logloss: 0.326118\tval's binary_logloss: 0.434624\n",
      "[154]\ttrain's binary_logloss: 0.325297\tval's binary_logloss: 0.434752\n",
      "[155]\ttrain's binary_logloss: 0.324526\tval's binary_logloss: 0.434965\n",
      "[156]\ttrain's binary_logloss: 0.323737\tval's binary_logloss: 0.435022\n",
      "[157]\ttrain's binary_logloss: 0.323309\tval's binary_logloss: 0.43498\n",
      "[158]\ttrain's binary_logloss: 0.322412\tval's binary_logloss: 0.435164\n",
      "[159]\ttrain's binary_logloss: 0.321956\tval's binary_logloss: 0.435101\n",
      "[160]\ttrain's binary_logloss: 0.321577\tval's binary_logloss: 0.435013\n",
      "[161]\ttrain's binary_logloss: 0.321154\tval's binary_logloss: 0.435011\n",
      "[162]\ttrain's binary_logloss: 0.32053\tval's binary_logloss: 0.435055\n",
      "[163]\ttrain's binary_logloss: 0.320052\tval's binary_logloss: 0.435117\n",
      "[164]\ttrain's binary_logloss: 0.319495\tval's binary_logloss: 0.435364\n",
      "[165]\ttrain's binary_logloss: 0.318879\tval's binary_logloss: 0.435365\n",
      "[166]\ttrain's binary_logloss: 0.318222\tval's binary_logloss: 0.435419\n",
      "[167]\ttrain's binary_logloss: 0.317357\tval's binary_logloss: 0.435392\n",
      "[168]\ttrain's binary_logloss: 0.316691\tval's binary_logloss: 0.435438\n",
      "[169]\ttrain's binary_logloss: 0.316256\tval's binary_logloss: 0.435394\n",
      "[170]\ttrain's binary_logloss: 0.315882\tval's binary_logloss: 0.435375\n",
      "[171]\ttrain's binary_logloss: 0.315545\tval's binary_logloss: 0.435288\n",
      "[172]\ttrain's binary_logloss: 0.314797\tval's binary_logloss: 0.435324\n",
      "[173]\ttrain's binary_logloss: 0.313944\tval's binary_logloss: 0.435237\n",
      "[174]\ttrain's binary_logloss: 0.313389\tval's binary_logloss: 0.435224\n",
      "[175]\ttrain's binary_logloss: 0.313052\tval's binary_logloss: 0.4353\n",
      "[176]\ttrain's binary_logloss: 0.312292\tval's binary_logloss: 0.435154\n",
      "[177]\ttrain's binary_logloss: 0.311895\tval's binary_logloss: 0.435003\n",
      "[178]\ttrain's binary_logloss: 0.311528\tval's binary_logloss: 0.434973\n",
      "[179]\ttrain's binary_logloss: 0.310734\tval's binary_logloss: 0.434731\n",
      "[180]\ttrain's binary_logloss: 0.31011\tval's binary_logloss: 0.434715\n",
      "[181]\ttrain's binary_logloss: 0.309429\tval's binary_logloss: 0.434621\n",
      "[182]\ttrain's binary_logloss: 0.308658\tval's binary_logloss: 0.434776\n",
      "[183]\ttrain's binary_logloss: 0.308014\tval's binary_logloss: 0.434838\n",
      "[184]\ttrain's binary_logloss: 0.307468\tval's binary_logloss: 0.434988\n",
      "[185]\ttrain's binary_logloss: 0.307104\tval's binary_logloss: 0.434971\n",
      "[186]\ttrain's binary_logloss: 0.306441\tval's binary_logloss: 0.434988\n",
      "[187]\ttrain's binary_logloss: 0.305569\tval's binary_logloss: 0.435141\n",
      "[188]\ttrain's binary_logloss: 0.305271\tval's binary_logloss: 0.435215\n",
      "[189]\ttrain's binary_logloss: 0.304607\tval's binary_logloss: 0.435181\n",
      "[190]\ttrain's binary_logloss: 0.303981\tval's binary_logloss: 0.435055\n",
      "[191]\ttrain's binary_logloss: 0.303315\tval's binary_logloss: 0.435251\n",
      "[192]\ttrain's binary_logloss: 0.30274\tval's binary_logloss: 0.435405\n",
      "[193]\ttrain's binary_logloss: 0.301864\tval's binary_logloss: 0.435372\n",
      "[194]\ttrain's binary_logloss: 0.301484\tval's binary_logloss: 0.435452\n",
      "[195]\ttrain's binary_logloss: 0.301014\tval's binary_logloss: 0.435727\n",
      "[196]\ttrain's binary_logloss: 0.300083\tval's binary_logloss: 0.435756\n",
      "[197]\ttrain's binary_logloss: 0.299544\tval's binary_logloss: 0.435986\n",
      "[198]\ttrain's binary_logloss: 0.299242\tval's binary_logloss: 0.436053\n",
      "[199]\ttrain's binary_logloss: 0.298515\tval's binary_logloss: 0.43649\n",
      "[200]\ttrain's binary_logloss: 0.298193\tval's binary_logloss: 0.436511\n",
      "[201]\ttrain's binary_logloss: 0.297521\tval's binary_logloss: 0.436551\n",
      "[202]\ttrain's binary_logloss: 0.296716\tval's binary_logloss: 0.436666\n",
      "[203]\ttrain's binary_logloss: 0.295858\tval's binary_logloss: 0.436609\n",
      "[204]\ttrain's binary_logloss: 0.295111\tval's binary_logloss: 0.43681\n",
      "[205]\ttrain's binary_logloss: 0.294636\tval's binary_logloss: 0.436886\n",
      "[206]\ttrain's binary_logloss: 0.293799\tval's binary_logloss: 0.437118\n",
      "[207]\ttrain's binary_logloss: 0.293252\tval's binary_logloss: 0.437264\n",
      "[208]\ttrain's binary_logloss: 0.29258\tval's binary_logloss: 0.437418\n",
      "[209]\ttrain's binary_logloss: 0.292261\tval's binary_logloss: 0.437434\n",
      "[210]\ttrain's binary_logloss: 0.291606\tval's binary_logloss: 0.437469\n",
      "[211]\ttrain's binary_logloss: 0.291045\tval's binary_logloss: 0.437558\n",
      "[212]\ttrain's binary_logloss: 0.290564\tval's binary_logloss: 0.43754\n",
      "[213]\ttrain's binary_logloss: 0.290205\tval's binary_logloss: 0.43755\n",
      "[214]\ttrain's binary_logloss: 0.289993\tval's binary_logloss: 0.437641\n",
      "[215]\ttrain's binary_logloss: 0.289417\tval's binary_logloss: 0.437635\n",
      "[216]\ttrain's binary_logloss: 0.288719\tval's binary_logloss: 0.43774\n",
      "[217]\ttrain's binary_logloss: 0.288504\tval's binary_logloss: 0.437777\n",
      "[218]\ttrain's binary_logloss: 0.287934\tval's binary_logloss: 0.43793\n",
      "[219]\ttrain's binary_logloss: 0.287508\tval's binary_logloss: 0.438196\n",
      "[220]\ttrain's binary_logloss: 0.286953\tval's binary_logloss: 0.438378\n",
      "[221]\ttrain's binary_logloss: 0.286314\tval's binary_logloss: 0.438319\n",
      "[222]\ttrain's binary_logloss: 0.285475\tval's binary_logloss: 0.438295\n",
      "[223]\ttrain's binary_logloss: 0.284867\tval's binary_logloss: 0.43833\n",
      "[224]\ttrain's binary_logloss: 0.284166\tval's binary_logloss: 0.438426\n",
      "[225]\ttrain's binary_logloss: 0.28362\tval's binary_logloss: 0.438208\n",
      "[226]\ttrain's binary_logloss: 0.282989\tval's binary_logloss: 0.43842\n",
      "[227]\ttrain's binary_logloss: 0.282301\tval's binary_logloss: 0.438607\n",
      "[228]\ttrain's binary_logloss: 0.281832\tval's binary_logloss: 0.438457\n",
      "[229]\ttrain's binary_logloss: 0.28132\tval's binary_logloss: 0.438614\n",
      "[230]\ttrain's binary_logloss: 0.28054\tval's binary_logloss: 0.438824\n",
      "[231]\ttrain's binary_logloss: 0.280026\tval's binary_logloss: 0.438863\n",
      "[232]\ttrain's binary_logloss: 0.27956\tval's binary_logloss: 0.438812\n",
      "[233]\ttrain's binary_logloss: 0.279157\tval's binary_logloss: 0.438906\n",
      "[234]\ttrain's binary_logloss: 0.27876\tval's binary_logloss: 0.439077\n",
      "[235]\ttrain's binary_logloss: 0.278232\tval's binary_logloss: 0.439069\n",
      "[236]\ttrain's binary_logloss: 0.277598\tval's binary_logloss: 0.439115\n",
      "[237]\ttrain's binary_logloss: 0.277383\tval's binary_logloss: 0.439168\n",
      "[238]\ttrain's binary_logloss: 0.276814\tval's binary_logloss: 0.439099\n",
      "[239]\ttrain's binary_logloss: 0.276113\tval's binary_logloss: 0.439041\n",
      "[240]\ttrain's binary_logloss: 0.275878\tval's binary_logloss: 0.439028\n",
      "[241]\ttrain's binary_logloss: 0.275332\tval's binary_logloss: 0.438959\n",
      "[242]\ttrain's binary_logloss: 0.275045\tval's binary_logloss: 0.438895\n",
      "[243]\ttrain's binary_logloss: 0.274489\tval's binary_logloss: 0.438907\n",
      "[244]\ttrain's binary_logloss: 0.274296\tval's binary_logloss: 0.438981\n",
      "[245]\ttrain's binary_logloss: 0.273753\tval's binary_logloss: 0.439018\n",
      "[246]\ttrain's binary_logloss: 0.273214\tval's binary_logloss: 0.439103\n",
      "[247]\ttrain's binary_logloss: 0.272726\tval's binary_logloss: 0.439223\n",
      "tr_logloss:  0.3306267544890511\n",
      "val_logloss:  0.4340127102761729\n",
      "predict:  [0.39638553 0.34273839 0.23514265 0.14554212 0.16483957 0.36111202\n",
      " 0.16796998 0.10459984 0.0929376  0.30083677]\n"
     ]
    }
   ],
   "source": [
    "gbdt_model(data.copy(), category_fea, continuous_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT+LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_lr_model(data, category_feature, continuous_feature):  # 0.43616\n",
    "    \"\"\"\n",
    "        GBDT+LR建模\n",
    "        \n",
    "        :param data: df, 数据表\n",
    "        :param category_fea: list, 离散特征列\n",
    "        :param continuous_fea: list, 连续特征列\n",
    "    \"\"\"\n",
    "    \n",
    "    # 离散特征one-hot编码\n",
    "    for col in category_feature:\n",
    "        onehot_feats = pd.get_dummies(data[col], prefix = col)\n",
    "        data.drop([col], axis = 1, inplace = True)\n",
    "        data = pd.concat([data, onehot_feats], axis = 1)\n",
    "\n",
    "    # 拆分训练集和测试集\n",
    "    train = data[data['Label'] != -1]\n",
    "    target = train.pop('Label')\n",
    "    test = data[data['Label'] == -1]\n",
    "    test.drop(['Label'], axis = 1, inplace = True)\n",
    "\n",
    "    # 划分数据集\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train, target, test_size = 0.2, random_state = 2020)\n",
    "\n",
    "    # 建立GBDT模型\n",
    "    gbm = lgb.LGBMClassifier(objective='binary',\n",
    "                            subsample= 0.8,\n",
    "                            min_child_weight= 0.5,\n",
    "                            colsample_bytree= 0.7,\n",
    "                            num_leaves=100,\n",
    "                            max_depth = 12,\n",
    "                            learning_rate=0.01,\n",
    "                            n_estimators=1000,\n",
    "                            )\n",
    "\n",
    "    gbm.fit(x_train, y_train,\n",
    "            eval_set = [(x_train, y_train), (x_val, y_val)],\n",
    "            eval_names = ['train', 'val'],\n",
    "            eval_metric = 'binary_logloss',\n",
    "            early_stopping_rounds = 100,\n",
    "            )\n",
    "    \n",
    "    # GBDT负责对各个特征进行交叉， 把原始特征向量转换为新的离散型特征向量\n",
    "    model = gbm.booster_\n",
    "\n",
    "    gbdt_feats_train = model.predict(train, pred_leaf = True)\n",
    "    gbdt_feats_test = model.predict(test, pred_leaf = True)\n",
    "    gbdt_feats_name = ['gbdt_leaf_' + str(i) for i in range(gbdt_feats_train.shape[1])]\n",
    "    df_train_gbdt_feats = pd.DataFrame(gbdt_feats_train, columns = gbdt_feats_name) \n",
    "    df_test_gbdt_feats = pd.DataFrame(gbdt_feats_test, columns = gbdt_feats_name)\n",
    "\n",
    "    # 新特征（连续特征 + 离散特征one-hot编码 + GBDT生成的离散特征）\n",
    "    train = pd.concat([train, df_train_gbdt_feats], axis = 1)\n",
    "    test = pd.concat([test, df_test_gbdt_feats], axis = 1)\n",
    "    train_len = train.shape[0]\n",
    "    data = pd.concat([train, test])    \n",
    "    del train\n",
    "    del test\n",
    "    gc.collect()  # 清理内存\n",
    "\n",
    "    # 连续特征归一化\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in continuous_feature:\n",
    "        data[col] = scaler.fit_transform(data[col].values.reshape(-1, 1))\n",
    "\n",
    "    # GBDT生成的离散特征one-hot编码\n",
    "    for col in gbdt_feats_name:\n",
    "        onehot_feats = pd.get_dummies(data[col], prefix = col)\n",
    "        data.drop([col], axis = 1, inplace = True)\n",
    "        data = pd.concat([data, onehot_feats], axis = 1)\n",
    "\n",
    "    train = data[: train_len]\n",
    "    test = data[train_len:]\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # 划分数据集\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train, target, test_size = 0.3, random_state = 2018)\n",
    "\n",
    "    # 建立逻辑回归模型\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    tr_logloss = log_loss(y_train, lr.predict_proba(x_train)[:, 1])\n",
    "    val_logloss = log_loss(y_val, lr.predict_proba(x_val)[:, 1])\n",
    "    print('tr-logloss: ', tr_logloss)\n",
    "    print('val-logloss: ', val_logloss)\n",
    "    \n",
    "    # 模型预测\n",
    "    y_pred = lr.predict_proba(test)[:, 1]\n",
    "    print(y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's binary_logloss: 0.523857\tval's binary_logloss: 0.457806\n",
      "[2]\ttrain's binary_logloss: 0.521371\tval's binary_logloss: 0.457213\n",
      "[3]\ttrain's binary_logloss: 0.519084\tval's binary_logloss: 0.456616\n",
      "[4]\ttrain's binary_logloss: 0.516882\tval's binary_logloss: 0.456046\n",
      "[5]\ttrain's binary_logloss: 0.514449\tval's binary_logloss: 0.455649\n",
      "[6]\ttrain's binary_logloss: 0.512277\tval's binary_logloss: 0.455319\n",
      "[7]\ttrain's binary_logloss: 0.509973\tval's binary_logloss: 0.455039\n",
      "[8]\ttrain's binary_logloss: 0.507717\tval's binary_logloss: 0.454523\n",
      "[9]\ttrain's binary_logloss: 0.505668\tval's binary_logloss: 0.454546\n",
      "[10]\ttrain's binary_logloss: 0.503491\tval's binary_logloss: 0.454134\n",
      "[11]\ttrain's binary_logloss: 0.501469\tval's binary_logloss: 0.453151\n",
      "[12]\ttrain's binary_logloss: 0.499463\tval's binary_logloss: 0.452609\n",
      "[13]\ttrain's binary_logloss: 0.497257\tval's binary_logloss: 0.452419\n",
      "[14]\ttrain's binary_logloss: 0.495206\tval's binary_logloss: 0.451944\n",
      "[15]\ttrain's binary_logloss: 0.493127\tval's binary_logloss: 0.451356\n",
      "[16]\ttrain's binary_logloss: 0.491215\tval's binary_logloss: 0.451181\n",
      "[17]\ttrain's binary_logloss: 0.489258\tval's binary_logloss: 0.450615\n",
      "[18]\ttrain's binary_logloss: 0.487424\tval's binary_logloss: 0.450754\n",
      "[19]\ttrain's binary_logloss: 0.485589\tval's binary_logloss: 0.450428\n",
      "[20]\ttrain's binary_logloss: 0.483753\tval's binary_logloss: 0.450043\n",
      "[21]\ttrain's binary_logloss: 0.481871\tval's binary_logloss: 0.449924\n",
      "[22]\ttrain's binary_logloss: 0.480233\tval's binary_logloss: 0.449518\n",
      "[23]\ttrain's binary_logloss: 0.478629\tval's binary_logloss: 0.449086\n",
      "[24]\ttrain's binary_logloss: 0.476933\tval's binary_logloss: 0.448878\n",
      "[25]\ttrain's binary_logloss: 0.47504\tval's binary_logloss: 0.448413\n",
      "[26]\ttrain's binary_logloss: 0.473416\tval's binary_logloss: 0.44809\n",
      "[27]\ttrain's binary_logloss: 0.471608\tval's binary_logloss: 0.448072\n",
      "[28]\ttrain's binary_logloss: 0.469969\tval's binary_logloss: 0.447721\n",
      "[29]\ttrain's binary_logloss: 0.46833\tval's binary_logloss: 0.447358\n",
      "[30]\ttrain's binary_logloss: 0.466517\tval's binary_logloss: 0.447445\n",
      "[31]\ttrain's binary_logloss: 0.464722\tval's binary_logloss: 0.447317\n",
      "[32]\ttrain's binary_logloss: 0.463079\tval's binary_logloss: 0.447152\n",
      "[33]\ttrain's binary_logloss: 0.461319\tval's binary_logloss: 0.446674\n",
      "[34]\ttrain's binary_logloss: 0.459722\tval's binary_logloss: 0.446455\n",
      "[35]\ttrain's binary_logloss: 0.457986\tval's binary_logloss: 0.446345\n",
      "[36]\ttrain's binary_logloss: 0.456293\tval's binary_logloss: 0.446229\n",
      "[37]\ttrain's binary_logloss: 0.454638\tval's binary_logloss: 0.446135\n",
      "[38]\ttrain's binary_logloss: 0.452929\tval's binary_logloss: 0.445476\n",
      "[39]\ttrain's binary_logloss: 0.451349\tval's binary_logloss: 0.445208\n",
      "[40]\ttrain's binary_logloss: 0.449759\tval's binary_logloss: 0.444538\n",
      "[41]\ttrain's binary_logloss: 0.448181\tval's binary_logloss: 0.444151\n",
      "[42]\ttrain's binary_logloss: 0.446656\tval's binary_logloss: 0.443786\n",
      "[43]\ttrain's binary_logloss: 0.445243\tval's binary_logloss: 0.443472\n",
      "[44]\ttrain's binary_logloss: 0.443697\tval's binary_logloss: 0.443249\n",
      "[45]\ttrain's binary_logloss: 0.442193\tval's binary_logloss: 0.443062\n",
      "[46]\ttrain's binary_logloss: 0.440697\tval's binary_logloss: 0.442784\n",
      "[47]\ttrain's binary_logloss: 0.439353\tval's binary_logloss: 0.442828\n",
      "[48]\ttrain's binary_logloss: 0.437963\tval's binary_logloss: 0.442524\n",
      "[49]\ttrain's binary_logloss: 0.436672\tval's binary_logloss: 0.442423\n",
      "[50]\ttrain's binary_logloss: 0.435301\tval's binary_logloss: 0.442193\n",
      "[51]\ttrain's binary_logloss: 0.433889\tval's binary_logloss: 0.441743\n",
      "[52]\ttrain's binary_logloss: 0.432548\tval's binary_logloss: 0.441336\n",
      "[53]\ttrain's binary_logloss: 0.431017\tval's binary_logloss: 0.441085\n",
      "[54]\ttrain's binary_logloss: 0.429677\tval's binary_logloss: 0.440932\n",
      "[55]\ttrain's binary_logloss: 0.428271\tval's binary_logloss: 0.440676\n",
      "[56]\ttrain's binary_logloss: 0.42698\tval's binary_logloss: 0.44047\n",
      "[57]\ttrain's binary_logloss: 0.425539\tval's binary_logloss: 0.440397\n",
      "[58]\ttrain's binary_logloss: 0.424123\tval's binary_logloss: 0.440136\n",
      "[59]\ttrain's binary_logloss: 0.422809\tval's binary_logloss: 0.439885\n",
      "[60]\ttrain's binary_logloss: 0.42146\tval's binary_logloss: 0.439716\n",
      "[61]\ttrain's binary_logloss: 0.420068\tval's binary_logloss: 0.439454\n",
      "[62]\ttrain's binary_logloss: 0.418745\tval's binary_logloss: 0.439493\n",
      "[63]\ttrain's binary_logloss: 0.41755\tval's binary_logloss: 0.439334\n",
      "[64]\ttrain's binary_logloss: 0.416342\tval's binary_logloss: 0.439451\n",
      "[65]\ttrain's binary_logloss: 0.415058\tval's binary_logloss: 0.439173\n",
      "[66]\ttrain's binary_logloss: 0.413658\tval's binary_logloss: 0.43881\n",
      "[67]\ttrain's binary_logloss: 0.4123\tval's binary_logloss: 0.438656\n",
      "[68]\ttrain's binary_logloss: 0.410981\tval's binary_logloss: 0.438352\n",
      "[69]\ttrain's binary_logloss: 0.409717\tval's binary_logloss: 0.438017\n",
      "[70]\ttrain's binary_logloss: 0.408442\tval's binary_logloss: 0.437799\n",
      "[71]\ttrain's binary_logloss: 0.407242\tval's binary_logloss: 0.437543\n",
      "[72]\ttrain's binary_logloss: 0.406051\tval's binary_logloss: 0.437359\n",
      "[73]\ttrain's binary_logloss: 0.404727\tval's binary_logloss: 0.437274\n",
      "[74]\ttrain's binary_logloss: 0.403419\tval's binary_logloss: 0.437135\n",
      "[75]\ttrain's binary_logloss: 0.402132\tval's binary_logloss: 0.437162\n",
      "[76]\ttrain's binary_logloss: 0.401026\tval's binary_logloss: 0.437043\n",
      "[77]\ttrain's binary_logloss: 0.399681\tval's binary_logloss: 0.436681\n",
      "[78]\ttrain's binary_logloss: 0.398398\tval's binary_logloss: 0.436374\n",
      "[79]\ttrain's binary_logloss: 0.397186\tval's binary_logloss: 0.436306\n",
      "[80]\ttrain's binary_logloss: 0.395998\tval's binary_logloss: 0.436238\n",
      "[81]\ttrain's binary_logloss: 0.394678\tval's binary_logloss: 0.436146\n",
      "[82]\ttrain's binary_logloss: 0.393508\tval's binary_logloss: 0.436026\n",
      "[83]\ttrain's binary_logloss: 0.392385\tval's binary_logloss: 0.435897\n",
      "[84]\ttrain's binary_logloss: 0.391328\tval's binary_logloss: 0.435948\n",
      "[85]\ttrain's binary_logloss: 0.390191\tval's binary_logloss: 0.435803\n",
      "[86]\ttrain's binary_logloss: 0.389034\tval's binary_logloss: 0.435726\n",
      "[87]\ttrain's binary_logloss: 0.388039\tval's binary_logloss: 0.435854\n",
      "[88]\ttrain's binary_logloss: 0.3868\tval's binary_logloss: 0.435683\n",
      "[89]\ttrain's binary_logloss: 0.38566\tval's binary_logloss: 0.435685\n",
      "[90]\ttrain's binary_logloss: 0.384527\tval's binary_logloss: 0.435758\n",
      "[91]\ttrain's binary_logloss: 0.383388\tval's binary_logloss: 0.435756\n",
      "[92]\ttrain's binary_logloss: 0.38231\tval's binary_logloss: 0.435815\n",
      "[93]\ttrain's binary_logloss: 0.381094\tval's binary_logloss: 0.435682\n",
      "[94]\ttrain's binary_logloss: 0.379807\tval's binary_logloss: 0.435561\n",
      "[95]\ttrain's binary_logloss: 0.37872\tval's binary_logloss: 0.435383\n",
      "[96]\ttrain's binary_logloss: 0.377682\tval's binary_logloss: 0.435011\n",
      "[97]\ttrain's binary_logloss: 0.376613\tval's binary_logloss: 0.434783\n",
      "[98]\ttrain's binary_logloss: 0.375463\tval's binary_logloss: 0.434865\n",
      "[99]\ttrain's binary_logloss: 0.374318\tval's binary_logloss: 0.434926\n",
      "[100]\ttrain's binary_logloss: 0.373331\tval's binary_logloss: 0.435077\n",
      "[101]\ttrain's binary_logloss: 0.372209\tval's binary_logloss: 0.43519\n",
      "[102]\ttrain's binary_logloss: 0.371232\tval's binary_logloss: 0.434997\n",
      "[103]\ttrain's binary_logloss: 0.370158\tval's binary_logloss: 0.43491\n",
      "[104]\ttrain's binary_logloss: 0.369108\tval's binary_logloss: 0.434854\n",
      "[105]\ttrain's binary_logloss: 0.368046\tval's binary_logloss: 0.435009\n",
      "[106]\ttrain's binary_logloss: 0.366972\tval's binary_logloss: 0.434982\n",
      "[107]\ttrain's binary_logloss: 0.365952\tval's binary_logloss: 0.435174\n",
      "[108]\ttrain's binary_logloss: 0.365084\tval's binary_logloss: 0.435282\n",
      "[109]\ttrain's binary_logloss: 0.364023\tval's binary_logloss: 0.435066\n",
      "[110]\ttrain's binary_logloss: 0.363132\tval's binary_logloss: 0.43526\n",
      "[111]\ttrain's binary_logloss: 0.362204\tval's binary_logloss: 0.435537\n",
      "[112]\ttrain's binary_logloss: 0.361217\tval's binary_logloss: 0.435766\n",
      "[113]\ttrain's binary_logloss: 0.360214\tval's binary_logloss: 0.43583\n",
      "[114]\ttrain's binary_logloss: 0.35936\tval's binary_logloss: 0.435792\n",
      "[115]\ttrain's binary_logloss: 0.358383\tval's binary_logloss: 0.435522\n",
      "[116]\ttrain's binary_logloss: 0.357288\tval's binary_logloss: 0.435637\n",
      "[117]\ttrain's binary_logloss: 0.356216\tval's binary_logloss: 0.435376\n",
      "[118]\ttrain's binary_logloss: 0.355096\tval's binary_logloss: 0.435324\n",
      "[119]\ttrain's binary_logloss: 0.354101\tval's binary_logloss: 0.43536\n",
      "[120]\ttrain's binary_logloss: 0.353266\tval's binary_logloss: 0.435261\n",
      "[121]\ttrain's binary_logloss: 0.352268\tval's binary_logloss: 0.435374\n",
      "[122]\ttrain's binary_logloss: 0.351148\tval's binary_logloss: 0.435321\n",
      "[123]\ttrain's binary_logloss: 0.350471\tval's binary_logloss: 0.435319\n",
      "[124]\ttrain's binary_logloss: 0.349503\tval's binary_logloss: 0.435183\n",
      "[125]\ttrain's binary_logloss: 0.348856\tval's binary_logloss: 0.435206\n",
      "[126]\ttrain's binary_logloss: 0.348053\tval's binary_logloss: 0.435206\n",
      "[127]\ttrain's binary_logloss: 0.347443\tval's binary_logloss: 0.434997\n",
      "[128]\ttrain's binary_logloss: 0.346512\tval's binary_logloss: 0.434941\n",
      "[129]\ttrain's binary_logloss: 0.345885\tval's binary_logloss: 0.434922\n",
      "[130]\ttrain's binary_logloss: 0.345112\tval's binary_logloss: 0.43477\n",
      "[131]\ttrain's binary_logloss: 0.344716\tval's binary_logloss: 0.434628\n",
      "[132]\ttrain's binary_logloss: 0.343697\tval's binary_logloss: 0.434359\n",
      "[133]\ttrain's binary_logloss: 0.342596\tval's binary_logloss: 0.434238\n",
      "[134]\ttrain's binary_logloss: 0.341666\tval's binary_logloss: 0.434321\n",
      "[135]\ttrain's binary_logloss: 0.340742\tval's binary_logloss: 0.434473\n",
      "[136]\ttrain's binary_logloss: 0.340167\tval's binary_logloss: 0.43421\n",
      "[137]\ttrain's binary_logloss: 0.339296\tval's binary_logloss: 0.434303\n",
      "[138]\ttrain's binary_logloss: 0.338391\tval's binary_logloss: 0.434198\n",
      "[139]\ttrain's binary_logloss: 0.337404\tval's binary_logloss: 0.434061\n",
      "[140]\ttrain's binary_logloss: 0.336569\tval's binary_logloss: 0.434292\n",
      "[141]\ttrain's binary_logloss: 0.335612\tval's binary_logloss: 0.43427\n",
      "[142]\ttrain's binary_logloss: 0.334555\tval's binary_logloss: 0.434261\n",
      "[143]\ttrain's binary_logloss: 0.333721\tval's binary_logloss: 0.434249\n",
      "[144]\ttrain's binary_logloss: 0.332994\tval's binary_logloss: 0.434215\n",
      "[145]\ttrain's binary_logloss: 0.332136\tval's binary_logloss: 0.434258\n",
      "[146]\ttrain's binary_logloss: 0.331524\tval's binary_logloss: 0.434092\n",
      "[147]\ttrain's binary_logloss: 0.330627\tval's binary_logloss: 0.434013\n",
      "[148]\ttrain's binary_logloss: 0.330059\tval's binary_logloss: 0.434193\n",
      "[149]\ttrain's binary_logloss: 0.329078\tval's binary_logloss: 0.434141\n",
      "[150]\ttrain's binary_logloss: 0.328427\tval's binary_logloss: 0.434367\n",
      "[151]\ttrain's binary_logloss: 0.327484\tval's binary_logloss: 0.434264\n",
      "[152]\ttrain's binary_logloss: 0.326809\tval's binary_logloss: 0.434526\n",
      "[153]\ttrain's binary_logloss: 0.326118\tval's binary_logloss: 0.434624\n",
      "[154]\ttrain's binary_logloss: 0.325297\tval's binary_logloss: 0.434752\n",
      "[155]\ttrain's binary_logloss: 0.324526\tval's binary_logloss: 0.434965\n",
      "[156]\ttrain's binary_logloss: 0.323737\tval's binary_logloss: 0.435022\n",
      "[157]\ttrain's binary_logloss: 0.323309\tval's binary_logloss: 0.43498\n",
      "[158]\ttrain's binary_logloss: 0.322412\tval's binary_logloss: 0.435164\n",
      "[159]\ttrain's binary_logloss: 0.321956\tval's binary_logloss: 0.435101\n",
      "[160]\ttrain's binary_logloss: 0.321577\tval's binary_logloss: 0.435013\n",
      "[161]\ttrain's binary_logloss: 0.321154\tval's binary_logloss: 0.435011\n",
      "[162]\ttrain's binary_logloss: 0.32053\tval's binary_logloss: 0.435055\n",
      "[163]\ttrain's binary_logloss: 0.320052\tval's binary_logloss: 0.435117\n",
      "[164]\ttrain's binary_logloss: 0.319495\tval's binary_logloss: 0.435364\n",
      "[165]\ttrain's binary_logloss: 0.318879\tval's binary_logloss: 0.435365\n",
      "[166]\ttrain's binary_logloss: 0.318222\tval's binary_logloss: 0.435419\n",
      "[167]\ttrain's binary_logloss: 0.317357\tval's binary_logloss: 0.435392\n",
      "[168]\ttrain's binary_logloss: 0.316691\tval's binary_logloss: 0.435438\n",
      "[169]\ttrain's binary_logloss: 0.316256\tval's binary_logloss: 0.435394\n",
      "[170]\ttrain's binary_logloss: 0.315882\tval's binary_logloss: 0.435375\n",
      "[171]\ttrain's binary_logloss: 0.315545\tval's binary_logloss: 0.435288\n",
      "[172]\ttrain's binary_logloss: 0.314797\tval's binary_logloss: 0.435324\n",
      "[173]\ttrain's binary_logloss: 0.313944\tval's binary_logloss: 0.435237\n",
      "[174]\ttrain's binary_logloss: 0.313389\tval's binary_logloss: 0.435224\n",
      "[175]\ttrain's binary_logloss: 0.313052\tval's binary_logloss: 0.4353\n",
      "[176]\ttrain's binary_logloss: 0.312292\tval's binary_logloss: 0.435154\n",
      "[177]\ttrain's binary_logloss: 0.311895\tval's binary_logloss: 0.435003\n",
      "[178]\ttrain's binary_logloss: 0.311528\tval's binary_logloss: 0.434973\n",
      "[179]\ttrain's binary_logloss: 0.310734\tval's binary_logloss: 0.434731\n",
      "[180]\ttrain's binary_logloss: 0.31011\tval's binary_logloss: 0.434715\n",
      "[181]\ttrain's binary_logloss: 0.309429\tval's binary_logloss: 0.434621\n",
      "[182]\ttrain's binary_logloss: 0.308658\tval's binary_logloss: 0.434776\n",
      "[183]\ttrain's binary_logloss: 0.308014\tval's binary_logloss: 0.434838\n",
      "[184]\ttrain's binary_logloss: 0.307468\tval's binary_logloss: 0.434988\n",
      "[185]\ttrain's binary_logloss: 0.307104\tval's binary_logloss: 0.434971\n",
      "[186]\ttrain's binary_logloss: 0.306441\tval's binary_logloss: 0.434988\n",
      "[187]\ttrain's binary_logloss: 0.305569\tval's binary_logloss: 0.435141\n",
      "[188]\ttrain's binary_logloss: 0.305271\tval's binary_logloss: 0.435215\n",
      "[189]\ttrain's binary_logloss: 0.304607\tval's binary_logloss: 0.435181\n",
      "[190]\ttrain's binary_logloss: 0.303981\tval's binary_logloss: 0.435055\n",
      "[191]\ttrain's binary_logloss: 0.303315\tval's binary_logloss: 0.435251\n",
      "[192]\ttrain's binary_logloss: 0.30274\tval's binary_logloss: 0.435405\n",
      "[193]\ttrain's binary_logloss: 0.301864\tval's binary_logloss: 0.435372\n",
      "[194]\ttrain's binary_logloss: 0.301484\tval's binary_logloss: 0.435452\n",
      "[195]\ttrain's binary_logloss: 0.301014\tval's binary_logloss: 0.435727\n",
      "[196]\ttrain's binary_logloss: 0.300083\tval's binary_logloss: 0.435756\n",
      "[197]\ttrain's binary_logloss: 0.299544\tval's binary_logloss: 0.435986\n",
      "[198]\ttrain's binary_logloss: 0.299242\tval's binary_logloss: 0.436053\n",
      "[199]\ttrain's binary_logloss: 0.298515\tval's binary_logloss: 0.43649\n",
      "[200]\ttrain's binary_logloss: 0.298193\tval's binary_logloss: 0.436511\n",
      "[201]\ttrain's binary_logloss: 0.297521\tval's binary_logloss: 0.436551\n",
      "[202]\ttrain's binary_logloss: 0.296716\tval's binary_logloss: 0.436666\n",
      "[203]\ttrain's binary_logloss: 0.295858\tval's binary_logloss: 0.436609\n",
      "[204]\ttrain's binary_logloss: 0.295111\tval's binary_logloss: 0.43681\n",
      "[205]\ttrain's binary_logloss: 0.294636\tval's binary_logloss: 0.436886\n",
      "[206]\ttrain's binary_logloss: 0.293799\tval's binary_logloss: 0.437118\n",
      "[207]\ttrain's binary_logloss: 0.293252\tval's binary_logloss: 0.437264\n",
      "[208]\ttrain's binary_logloss: 0.29258\tval's binary_logloss: 0.437418\n",
      "[209]\ttrain's binary_logloss: 0.292261\tval's binary_logloss: 0.437434\n",
      "[210]\ttrain's binary_logloss: 0.291606\tval's binary_logloss: 0.437469\n",
      "[211]\ttrain's binary_logloss: 0.291045\tval's binary_logloss: 0.437558\n",
      "[212]\ttrain's binary_logloss: 0.290564\tval's binary_logloss: 0.43754\n",
      "[213]\ttrain's binary_logloss: 0.290205\tval's binary_logloss: 0.43755\n",
      "[214]\ttrain's binary_logloss: 0.289993\tval's binary_logloss: 0.437641\n",
      "[215]\ttrain's binary_logloss: 0.289417\tval's binary_logloss: 0.437635\n",
      "[216]\ttrain's binary_logloss: 0.288719\tval's binary_logloss: 0.43774\n",
      "[217]\ttrain's binary_logloss: 0.288504\tval's binary_logloss: 0.437777\n",
      "[218]\ttrain's binary_logloss: 0.287934\tval's binary_logloss: 0.43793\n",
      "[219]\ttrain's binary_logloss: 0.287508\tval's binary_logloss: 0.438196\n",
      "[220]\ttrain's binary_logloss: 0.286953\tval's binary_logloss: 0.438378\n",
      "[221]\ttrain's binary_logloss: 0.286314\tval's binary_logloss: 0.438319\n",
      "[222]\ttrain's binary_logloss: 0.285475\tval's binary_logloss: 0.438295\n",
      "[223]\ttrain's binary_logloss: 0.284867\tval's binary_logloss: 0.43833\n",
      "[224]\ttrain's binary_logloss: 0.284166\tval's binary_logloss: 0.438426\n",
      "[225]\ttrain's binary_logloss: 0.28362\tval's binary_logloss: 0.438208\n",
      "[226]\ttrain's binary_logloss: 0.282989\tval's binary_logloss: 0.43842\n",
      "[227]\ttrain's binary_logloss: 0.282301\tval's binary_logloss: 0.438607\n",
      "[228]\ttrain's binary_logloss: 0.281832\tval's binary_logloss: 0.438457\n",
      "[229]\ttrain's binary_logloss: 0.28132\tval's binary_logloss: 0.438614\n",
      "[230]\ttrain's binary_logloss: 0.28054\tval's binary_logloss: 0.438824\n",
      "[231]\ttrain's binary_logloss: 0.280026\tval's binary_logloss: 0.438863\n",
      "[232]\ttrain's binary_logloss: 0.27956\tval's binary_logloss: 0.438812\n",
      "[233]\ttrain's binary_logloss: 0.279157\tval's binary_logloss: 0.438906\n",
      "[234]\ttrain's binary_logloss: 0.27876\tval's binary_logloss: 0.439077\n",
      "[235]\ttrain's binary_logloss: 0.278232\tval's binary_logloss: 0.439069\n",
      "[236]\ttrain's binary_logloss: 0.277598\tval's binary_logloss: 0.439115\n",
      "[237]\ttrain's binary_logloss: 0.277383\tval's binary_logloss: 0.439168\n",
      "[238]\ttrain's binary_logloss: 0.276814\tval's binary_logloss: 0.439099\n",
      "[239]\ttrain's binary_logloss: 0.276113\tval's binary_logloss: 0.439041\n",
      "[240]\ttrain's binary_logloss: 0.275878\tval's binary_logloss: 0.439028\n",
      "[241]\ttrain's binary_logloss: 0.275332\tval's binary_logloss: 0.438959\n",
      "[242]\ttrain's binary_logloss: 0.275045\tval's binary_logloss: 0.438895\n",
      "[243]\ttrain's binary_logloss: 0.274489\tval's binary_logloss: 0.438907\n",
      "[244]\ttrain's binary_logloss: 0.274296\tval's binary_logloss: 0.438981\n",
      "[245]\ttrain's binary_logloss: 0.273753\tval's binary_logloss: 0.439018\n",
      "[246]\ttrain's binary_logloss: 0.273214\tval's binary_logloss: 0.439103\n",
      "[247]\ttrain's binary_logloss: 0.272726\tval's binary_logloss: 0.439223\n",
      "tr-logloss:  0.012043875601048087\n",
      "val-logloss:  0.30527705372305236\n",
      "[9.42504639e-01 2.76597656e-01 2.27699953e-02 1.86025096e-02\n",
      " 4.45934326e-03 6.48474724e-01 6.80003741e-03 3.57831915e-03\n",
      " 4.16062509e-04 5.44962925e-02]\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_model(data.copy(), category_fea, continuous_fea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "| Model | train's binary_logloss | val's binary_logloss |\n",
    "| :---- | -----: | :----:|\n",
    "| LR | 0.124234 | 0.444072 |\n",
    "| GBDT | 0.330627 | 0.434013 |\n",
    "| GBDT+LR | 0.012044 | 0.305277 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
